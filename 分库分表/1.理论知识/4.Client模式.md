### TDDL

#### TDDL的简介

TDDL（Taobao Distributed Data Layer）框架，==主要解决了分库分表对应用的透明化已经异构数据库之间的数据复制，它是一个基于集中式配置的jdbc datasource实现，具有主备，读写分离，动态数据库配置等功能。==

TDDL是在持久层之下、JDBC驱动之上的中间件，它与JDBC规范保持一致，有效解决了分库分表的规则引擎问题，==实现了SQL解析、规则计算、表名替换、选择执行单元并合并结果集的功能==，同时解决了数据库的读写分离、高性能主备切换的问题，实现了数据库配置信息的统一管理。
![[Pasted image 20221216094633.png]]

==注： TDDL必须要依赖diamond配置中心（diamond是淘宝内部使用的一个管理持久配置的系统，目前淘宝内部绝大多数系统的配置，由diamond来进行统一管理，同时diamond也已开源）。==

==并且 TDDL的核心层Matrix尚未开源==

#### TDDL的三层结构
1. ==Matrix层分库分表、SQL解释、优化和执行等。==
2. Group层是经过读写分离和主备切换才会出现的最底层。
3. Atom层，它面对的是实实在在的每一个数据库，更多的工作在于对数据库的连接管理，比如当数据库的IP地址发生改变时，Atom层要动态感知，以免连接找不到地址。

![[Pasted image 20221216095406.png]]

#### TDDL 执行流程

![[Pasted image 20221216100545.png]]
TDDL的工作流程类似上图，==client发送一条SQL的执行语句，会优先传递给Matrix层。由Matrix解释SQL语句，优化，并根据查询条件路由到各个Group，转发SQL进行查询，各个Group根据权重选择其中一个Atom进行查询，各个Atom再将结果返回给Matrix，Matrix将结果合并返回给client。==具体的工作流程可以拆分成如下图。

![[Pasted image 20221216101135.png]]

##### #Matrix层 

Matrix层会先执行以下4个过程：
1. ==Sql的解析。==首先将Sql语句解析成一颗抽象语法树（Abstract Syntax Tree），解析成我们比较好处理的一个结构
2. 规则的匹配与计算。基于上一步创建的语法树查找匹配的规则，再根据规则去确定分库分表的结果。==这里有一个概念就是规则，规则这里可以简单的看做就是定义数据库怎么进行分库分表，要分成几张库几张表，库名和表名的命名是怎么样的。==规则的匹配就是根据SQL的语句确定，具体查询的子表是哪几张。
3. 表名替换。对于开发人员来说，它查询的表就是直接select * from A.B limit 10(A为数据库名，B为数据表名)。==但底层其实会把这些表名替换成==类似select * from A_000.B_001，select * from A_000.B.002，select * from A_001.TABLE_001这样的形式。==表名替换就是把总表的名称替换为这些子表的名字。==
4. Sql的转发。将上一步生成的各个Sql语句转发到对应的Group进行执行。这里如上图，我查询的条件时where id = 2 or 3。==那么转发给Group0的查询为where id=3，转发给group1的查询为where id = 2。查询的条件也会发生一定修改。==

这样4个步骤可以在Matrix层就实现了分库分表的功能，对原始的Sql进行分解，将原本单库单表的查询语句，底层转发到多库多表并行的进行执行，提高了数据库读写的性能。

##### #Group层

由Group层执行两个过程：
1. 根据==权重==选择AtomDs。通常会在主节点和副节点上读取数据，只在主节点上写入数据。
2. 具有==重试的策略==地在AtomDs上执行SQL。这个可以防止单个的AtomDs发生故障，那么会进入读重试，以确保尽可能多的数据访问可以在正常数据库中访问。

##### #Atom层

Atom层执行两个过程：
1. 读写数控制、线程并发数控制。同时会统计线程数、执行次数等信息。
2. ==执行sql，返回结果集。==Atom底层利用druid进行连接池的管理，具体查询还是对JDBC做了一定封装。执行完Sql后将结果返回给Matrix。

##### #Matrix层 

最后由Matrix执行合并
1. 结果集合并。Matrix将Atom层的返回的各个结果集进行合并Merge，返回给Client端。

### ShardingSphere-JDBC

#### ShardingSphere介绍
Apache ShardingSphere 设计哲学为 Database Plus，==旨在构建异构数据库上层的标准和生态。 它关注如何充分合理地利用数据库的计算和存储能力，而并非实现一个全新的数据库。 它站在数据库的上层视角，关注它们之间的协作多于数据库自身。==

![[Pasted image 20221216135410.png]]

Apache ShardingSphere 由 ==ShardingSphere-JDBC==和==ShardingSphere-Proxy==这2款既能够独立部署，又支持混合部署配合使用的产品组成。它们均提供标准化的基于数据库作为存储节点的增量功能，可适用于如Java同构、异构语言、云原生等各种多样化的应用场景。

#### #ShardingSphere-JDBC

ShardingSphere定位为轻量级Java框架，在Java的JDBC层提供的额外服务。它使用客户端直连数据库，==以jar包形式提供服务，无需额外部署和依赖，可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM框架。==
1. 适用于任何基于JDBC的ORM框架，如：JPA、Hibernate、Mybatis、Spring JDBC Template或直接使用JDBC；
2. 支持任何第三方的数据库连接池，如：DBCP、C3P0、BoneCp、HikariCp等；
3. 支持任意实现JDBC规范的数据库，目前支持Mysql、PostgreSQL、Oracle、SQLServer以及任何可使用JDBC访问的数据库。![[Pasted image 20221216141321.png]]

#### #ShardingSphere-JDBC执行过程

##### #SQL解析 

当Sharding-JDBC接受到一条SQL语句时，会陆续执行==SQL解析 => 查询优化 => SQL路由 => SQL改写 => SQl执行 =>结果归并==，最终返回执行结果。![[Pasted image 20221216155525.png]]

SQL解析过程分为==词法解析==和==语法解析==。词法解析器用于将SQL拆解为不可再分的原子符号，称为Token。并根据不同数据库方言所提供的字典，将其归类为==关键字，表达式，字面量和操作符==。再使用语法解析器将SQL转换为抽象语法树。例如以下SQL：

	SELECT id, name FROM t_user WHERE status = 'ACTIVE' AND age > 18

解析之后的为抽象语法树见下图：![[Pasted image 20221216160037.png]]

通过对抽象语法树的遍历去提炼分片所需的上下文，并标记有可能需要SQL改写（后边介绍）的未知，供分片使用的解析上下文包含==查询选择项（Select Items）、表信息（Table）、分片条件（Sharding Condition）、自增主键信息（Auto increment Primary Key）、排序信息（Order By）、分组信息（Group By）以及分页信息（Limit、Rownum、Top）。==

##### #SQL路由

SQL路由就是把针对逻辑表的数据操作映射到对数据结点操作的过程。

1. 分片路由
	1. 直接路由
	2. 标准路由
	3. 笛卡尔路由
2. 广播路由
	1. 全库表路由
	2. 全库路由
	3. 全实例路由
	4. 单播路由
	5. 阻断路由

根据解析上下文匹配数据库和表的分片策略，并生成路由路径。

对于携带分片键的SQL，根据分片键操作符不同可以划分为==单片路由==（分片键的操作符是等号）、==多片路由==（分片键的操作符是IN）和==范围路由==（分片键的操作符是BETWEEN），不携带分片键的SQL则采用==广播路由==。

###### #标准路由

标准路由是 ShardingSphere ==最为推荐==使用的分片方式，它的适用范围是==不包含关联查询或仅包含绑定表之间关联查询的SQL。== 当分片运算符是==等号==时，路由结果将落入单库（表），当分片运算符是==BETWEEN或IN==时，则路由结果不一定落入唯一的库（表），因此一条逻辑SQL最终可能被==拆分为多条用于执行的真实SQL。==举例说明，如果按照 order_id 的奇数和偶数进行数据分片，一个单表查询的SQL如下：

	SELECT * FROM t_order WHERE order_id IN (1, 2);
那么路由的结果应为：

	SELECT * FROM t_order_0 WHERE order_id IN (1, 2);
	SELECT * FROM t_order_1 WHERE order_id IN (1, 2);

==绑定表的关联查询与单表查询复杂度和性能相当==。举例说明，如果一个==包含绑定表==的关联查询SQL如下：

	SELECT * FROM t_order o JOIN t_order_item i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);

那么路由的结果应为：

	SELECT * FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);  SELECT * FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);

==SQL拆分的数目与单表是一致的。==

###### #笛卡尔路由

笛卡尔路由是最复杂的情况，它无法根据绑定表的关系定位分片规则，因此非绑定表之间的关联查询需要拆解为笛卡尔积组合执行。如果上个示例中的SQL并未配置绑定表关系，那么路由的结果应为：

	SELECT * FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);  SELECT * FROM t_order_0 o JOIN t_order_item_1 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);  SELECT * FROM t_order_1 o JOIN t_order_item_0 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);  SELECT * FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);

笛卡尔路由==查询性能较低==，需谨慎使用。全库表路由对于==不携带分片键==的SQL，则采取广播路由的方式。根据SQL类型又可以划分为==全库表路由==、==全库路由==、==全实例路由==、==单播路由==和==阻断路由==这5种类型。其中全库表路由用于处理对数据库中与其逻辑表相关的所有真实表的操作，主要包括不带分片键的DQL（数据查询）和DML（数据操纵），以及DDL（数据定义）等。例如：

	SELECT * FROM t_order WHERE good_prority IN (1, 10);

==则会遍历所有数据库中的所有表，逐一匹配逻辑表和真实表名==，能够匹配得上则执行。路由后成为

	SELECT * FROM t_order_0 WHERE good_prority IN (1, 10);  
	SELECT * FROM t_order_1 WHERE good_prority IN (1, 10);  
	SELECT * FROM t_order_2 WHERE good_prority IN (1, 10);  
	SELECT * FROM t_order_3 WHERE good_prority IN (1, 10);

##### #SQL改写

工程师面向逻辑表书写的SQL，并不能够直接在真实的数据库中执行，==SQL改写用于将逻辑SQL改写为在真实数据库中可以正确执行的SQL。==如一个简单的例子，若逻辑SQL为：

	SELECT order_id FROM t_order WHERE order_id=1;

假设该SQL配置分片键order_id，并且order_id=1的情况，将路由至分片表1。那么改写之后的SQL应该为：

	SELECT order_id FROM t_order_1 WHERE order_id=1;

##### #补列

再比如，Sharding-JDBC需要在结果归并时获取相应数据，但该数据并未能通过查询的SQL返回。这种情况主要是针对Group By和Order By。==结果归并时，需要根据Group By和Order By的字段项进行分组和排序，但如果原始SQL的选择项中并未包含分组或排序项，则需要对原始SQL进行改写。==先看一下原始SQL中带有结果归并所需信息的场景：

	SELECT order_id, user_id FROM t_order ORDER BY user_id;

由于使用user_id进行排序，在结果归并中需要能够获取到user_id的数据，而上面的SQL是能够获取到user_id数据的，因此无需补列。==如果选择项中不包含结果归并时所需的列，则需要进行补列，==如以下SQL：

	SELECT order_id FROM t_order ORDER BY user_id;

==由于原始SQL中并不包含需要在结果归并中需要获取的user_id，因此需要对SQL进行补列改写。==补列之后的SQL是：

	SELECT order_id, user_id AS ORDER_BY_DERIVED_0 FROM t_order ORDER BY user_id;

补列的另一种情况是==使用 AVG 聚合函数==。在分布式的场景中，使用 avg1 + avg2 + avg3 / 3 计算平均值并不正确，需要改写为（sum1 + sum2 + sum3) / (count1 + count2 + count3)。==这就需要将包含 AVG 的SQL改写为 SUM 和 COUNT== ，并在结果归并时重新计算平均值。例如以下SQL：

	SELECT AVG(price) FROM t_order WHERE user_id=1;

需要改写为：

	SELECT COUNT(price) AS AVG_DERIVED_COUNT_0, SUM(price) AS AVG_DERIVED_SUM_0 FROM t_order WHERE user_id = 1;

==然后才能结果归并正确的计算平均值。==

##### #分页修正

从多个数据库获取分页数据与单数据库的场景是不同的。假设每10条数据为一页，取第2页数据。==在分片环境下获取 LIMIT 10, 10，归并之后再根据排序条件取出前10条数据是不正确的。==举例说明，若SQL为：
	SELECT score FROM t_score ORDER BY score DESC LIMIT 1, 2;

下图展示了不进行 SQL 的改写的分页执行结果。![[Pasted image 20221216180232.png]]
正确的做法是将分页条件改写为 LIMIT 0,3 ，取出所有前两页数据，再结合排序条件计算出正确的数据。下图展示了进行SQL改写之后的分页执行结果。![[Pasted image 20221226155256.png]]
==越获取偏移量位置靠后数据，使用LIMIT分页方式的效率就越低。==有很多方法可以避免使用LIMIT进行分页。比如构建行记录数量与行偏移量的二级索引，或==使用上次分页数据结尾ID==作为下次查询条件的分页方式等。

分页信息修正时，如果使用占位符的方式书写SQL，则只需要改写参数列表即可，无需改写SQL本身。

##### #SQL执行

1. 连接模式
	1. 内存限制模式
	2. 连接限制模式
2. 自动化执行引擎
	1. 准备阶段
	2. 执行阶段

###### #内存限制模式

==使用此模式的前提是，ShardingSphere 对一次操作所耗费的数据库连接数量不做限制。==如果实际执行的SQL需要对某数据库实例中的200张表做操作，==则对每张表创建一个新的数据库连接==，并通过多线程的方式并发处理，以达成执行效率最大化。并且在SQL满足条件情况下，优先选择流式归并，以防止出现内存溢出或避免频繁垃圾回收情况。

###### #连接限制模式

使用此模式的前提是，ShardingSphere严格控制对一次操作所耗费的数据库连接数量。如果实际执行的SQL需要对某数据库实例中的200张表做操作，==那么只会创建唯一的数据库连接，并对其200张表串行处理==。如果一次操作中的分片散落在不同的数据库，仍然采用多线程处理对不同库的操作，但每个库的==每次操作仍然只创建一个唯一的数据库连接。==这样既可以防止对一次请求对数据库连接占用过多所带来的的问题。==该模式始终选择内存归并。==

==内存限制模式适用于OLAP操作，可以通过放宽对数据库连接的限制提升系统吞吐量；连接限制模式适用于OLTP操作，OLTP通常带有分片键，会路由到单一的分片，因此严格控制数据库连接，以保证在线系统数据库资源能够被更多的应用所使用的，是明智的选择。==

###### #自动化执行引擎

两种模式的切换交由静态的初始化配置，是缺乏灵活应对能力的。在实际的使用场景中，面对不同的SQL以及占位符参数，每次的路由结果是不同的。这就意味着某些操作可能需要使用内存归并，而某些操作则可能选择流式归并更优，具体采用哪种方式不应该由用户在ShardingSphere启动之前配置好，而是应该根据SQL和占位符参数的场景，来动态的决定连接模式。==用户无需了解所谓的内存限制模式和连接限制模式是什么，而是交由执行引擎根据当前场景自动选择最优的执行方案。==

==自动化执行引擎将连接模式的选择粒度细化至每一次SQL的操作。==针对每次SQL请求，自动化执行引擎都将根据其路由结果，进行实时的演算和权衡，==并自主地采用恰当的连接模式执行，以达到资源控制和效率的最优平衡。==

#准备阶段

此阶段用于准备执行的数据。它分为==结果集分组和执行单元==创建两个步骤。

1. 将SQL的路由结果按照数据源的名称进行分组。
2. 通过下图的公式，可以获得每个数据库实例在maxConnectionSizePerQuery的允许范围内，每个连接需要执行的SQL路由结果组，并计算出本次请求的最优连接模式。![[Pasted image 20221227095632.png]]
在maxConnectionSizePerQuery允许的范围内，==当一个连接需要执行的请求数量大于1时，意味着当前的数据库连接无法持有相应的数据结果集，则必须采用内存归并；反之，当一个连接需要执行的请求数量等于1时，意味着当前的数据库连接可以持有相应的数据结果集，则可以采用流式归并。==

每一次的连接模式的选择，是针对每一个物理数据库的。在同一次查询中，如果路由至一个以上的数据库，每个数据库的连接模式不一定一样，==他们可能是混合存在的形态。==

当数据源使用数据库连接池等控制数据库连接数量的技术时，在获取数据库连接时，如果不妥善处理并发，则有一定几率发生死锁。在多个请求相互等待对方释放数据库连接资源时，将会产生饥饿等待，造成交叉的死锁问题。

假设一次查询需要在某一数据源上获取两个数据库连接，并路由至同一个数据库的两个分表查询。则有可能出现查询A已获取到该数据源的1个数据库连接，并等待获取另一个数据库连接；而查询B也已经在该数据源上获取到的一个数据库连接，并同样等待另一个数据库连接的获取。如果数据库连接池的允许最大连接数是2，那么这2个查询请求将永久的等待下去。下图描绘了死锁的情况。![[Pasted image 20221227101017.png]]

> ShardingSphere 为了==避免死锁==的出现，在获取数据库连接时进行了==同步处理==。它在创建执行单元时，==以原子性的方式一次性获取本次SQL请求所需的全部数据库连接，杜绝了每次查询请求获取到部分资源的可能。==由于对数据库的操作非常频繁，每次获取数据库连接时都进行锁定，会降低ShardingSphere的并发。因此，ShardingSphere在这里进行了==2点优化==：
> 
>1. ==避免锁定一次性只需要获取1个数据库连接的操作==。因为每次仅需要获取1个连接，则不会发生两个请求互相等待的场景，无需锁定。对于大部分OLTP的操作，都是使用分片键路由至唯一的数据节点，这会使得系统变为完全无锁的状态，进一步提升了并发效率。除了路由至单分片的情况，读写分离也在此范畴之内。
>2. ==仅针对内存限制模式时才进行资源锁定。==在使用连接限制模式时，所有的查询结果集将在装载至内存之后释放掉数据库连接资源，因此不会产生死锁等待的问题。

#执行阶段

该阶段用于真正的执行SQL，它分为==分组执行==和==归并结果集生成==两个步骤。

分组执行将准备执行阶段生成的执行单元分组下发至底层并发执行引擎，并针对执行过程中的每个关键步骤发送事件。如：==执行开始事件==、==执行成功事件==以及==执行失败事件==。==执行引擎仅关注事件的发送==，它并不关心事件的订阅者。ShardingSphere的==其他模块==，如：分布式事务、调用链路追踪等，会订阅感兴趣的事件，并进行相应的处理。

ShardingSphere通过在执行准备阶段获取的连接模式，==生成内存归并结果集或流式归并结果集，并将其传递至结果归并引擎，==以进行下一步的工作。

执行引擎的整体结构划分如下图所示。![[Pasted image 20221227111420.png]]

##### #结果归并

将从各个数据节点获取的多数据结果集，组合成为一个结果集并正确的返回至请求客户端，称为结果归并。

Sharding-JDBC支持的结果归并从功能上可分为遍历、排序、分组、分页和聚合5种类型，它们是组合而非互斥的关系。归并引擎的整体结构划分如下图。![[Pasted image 20221227111708.png]]