### TDDL

#### TDDL的简介

TDDL（Taobao Distributed Data Layer）框架，==主要解决了分库分表对应用的透明化已经异构数据库之间的数据复制，它是一个基于集中式配置的jdbc datasource实现，具有主备，读写分离，动态数据库配置等功能。==

TDDL是在持久层之下、JDBC驱动之上的中间件，它与JDBC规范保持一致，有效解决了分库分表的规则引擎问题，==实现了SQL解析、规则计算、表名替换、选择执行单元并合并结果集的功能==，同时解决了数据库的读写分离、高性能主备切换的问题，实现了数据库配置信息的统一管理。
![[Pasted image 20221216094633.png]]

==注： TDDL必须要依赖diamond配置中心（diamond是淘宝内部使用的一个管理持久配置的系统，目前淘宝内部绝大多数系统的配置，由diamond来进行统一管理，同时diamond也已开源）。==

==并且 TDDL的核心层Matrix尚未开源==

#### TDDL的三层结构
1. ==Matrix层分库分表、SQL解释、优化和执行等。==
2. Group层是经过读写分离和主备切换才会出现的最底层。
3. Atom层，它面对的是实实在在的每一个数据库，更多的工作在于对数据库的连接管理，比如当数据库的IP地址发生改变时，Atom层要动态感知，以免连接找不到地址。

![[Pasted image 20221216095406.png]]

#### TDDL 执行流程

![[Pasted image 20221216100545.png]]
TDDL的工作流程类似上图，==client发送一条SQL的执行语句，会优先传递给Matrix层。由Matrix解释SQL语句，优化，并根据查询条件路由到各个Group，转发SQL进行查询，各个Group根据权重选择其中一个Atom进行查询，各个Atom再将结果返回给Matrix，Matrix将结果合并返回给client。==具体的工作流程可以拆分成如下图。

![[Pasted image 20221216101135.png]]

##### #Matrix层 

Matrix层会先执行以下4个过程：
1. ==Sql的解析。==首先将Sql语句解析成一颗抽象语法树（Abstract Syntax Tree），解析成我们比较好处理的一个结构
2. 规则的匹配与计算。基于上一步创建的语法树查找匹配的规则，再根据规则去确定分库分表的结果。==这里有一个概念就是规则，规则这里可以简单的看做就是定义数据库怎么进行分库分表，要分成几张库几张表，库名和表名的命名是怎么样的。==规则的匹配就是根据SQL的语句确定，具体查询的子表是哪几张。
3. 表名替换。对于开发人员来说，它查询的表就是直接select * from A.B limit 10(A为数据库名，B为数据表名)。==但底层其实会把这些表名替换成==类似select * from A_000.B_001，select * from A_000.B.002，select * from A_001.TABLE_001这样的形式。==表名替换就是把总表的名称替换为这些子表的名字。==
4. Sql的转发。将上一步生成的各个Sql语句转发到对应的Group进行执行。这里如上图，我查询的条件时where id = 2 or 3。==那么转发给Group0的查询为where id=3，转发给group1的查询为where id = 2。查询的条件也会发生一定修改。==

这样4个步骤可以在Matrix层就实现了分库分表的功能，对原始的Sql进行分解，将原本单库单表的查询语句，底层转发到多库多表并行的进行执行，提高了数据库读写的性能。

##### #Group层

由Group层执行两个过程：
1. 根据==权重==选择AtomDs。通常会在主节点和副节点上读取数据，只在主节点上写入数据。
2. 具有==重试的策略==地在AtomDs上执行SQL。这个可以防止单个的AtomDs发生故障，那么会进入读重试，以确保尽可能多的数据访问可以在正常数据库中访问。

##### #Atom层

Atom层执行两个过程：
1. 读写数控制、线程并发数控制。同时会统计线程数、执行次数等信息。
2. ==执行sql，返回结果集。==Atom底层利用druid进行连接池的管理，具体查询还是对JDBC做了一定封装。执行完Sql后将结果返回给Matrix。

##### #Matrix层 

最后由Matrix执行合并
1. 结果集合并。Matrix将Atom层的返回的各个结果集进行合并Merge，返回给Client端。

### ShardingSphere-JDBC

#### ShardingSphere介绍
Apache ShardingSphere 设计哲学为 Database Plus，==旨在构建异构数据库上层的标准和生态。 它关注如何充分合理地利用数据库的计算和存储能力，而并非实现一个全新的数据库。 它站在数据库的上层视角，关注它们之间的协作多于数据库自身。==

![[Pasted image 20221216135410.png]]

Apache ShardingSphere 由 ==ShardingSphere-JDBC==和==ShardingSphere-Proxy==这2款既能够独立部署，又支持混合部署配合使用的产品组成。它们均提供标准化的基于数据库作为存储节点的增量功能，可适用于如Java同构、异构语言、云原生等各种多样化的应用场景。

#### #ShardingSphere-JDBC

ShardingSphere定位为轻量级Java框架，在Java的JDBC层提供的额外服务。它使用客户端直连数据库，==以jar包形式提供服务，无需额外部署和依赖，可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM框架。==
1. 适用于任何基于JDBC的ORM框架，如：JPA、Hibernate、Mybatis、Spring JDBC Template或直接使用JDBC；
2. 支持任何第三方的数据库连接池，如：DBCP、C3P0、BoneCp、HikariCp等；
3. 支持任意实现JDBC规范的数据库，目前支持Mysql、PostgreSQL、Oracle、SQLServer以及任何可使用JDBC访问的数据库。![[Pasted image 20221216141321.png]]

#### ShardingSphere-JDBC执行过程

##### #SQL解析 

当Sharding-JDBC接受到一条SQL语句时，会陆续执行==SQL解析 => 查询优化 => SQL路由 => SQL改写 => SQl执行 =>结果归并==，最终返回执行结果。![[Pasted image 20221216155525.png]]

SQL解析过程分为==词法解析==和==语法解析==。词法解析器用于将SQL拆解为不可再分的原子符号，称为Token。并根据不同数据库方言所提供的字典，将其归类为==关键字，表达式，字面量和操作符==。再使用语法解析器将SQL转换为抽象语法树。例如以下SQL：

	SELECT id, name FROM t_user WHERE status = 'ACTIVE' AND age > 18

解析之后的为抽象语法树见下图：![[Pasted image 20221216160037.png]]

通过对抽象语法树的遍历去提炼分片所需的上下文，并标记有可能需要SQL改写（后边介绍）的未知，供分片使用的解析上下文包含==查询选择项（Select Items）、表信息（Table）、分片条件（Sharding Condition）、自增主键信息（Auto increment Primary Key）、排序信息（Order By）、分组信息（Group By）以及分页信息（Limit、Rownum、Top）。==

##### #SQL路由

SQL路由就是把针对逻辑表的数据操作映射到对数据结点操作的过程。

1. 分片路由
	1. 直接路由
	2. 标准路由
	3. 笛卡尔路由
2. 广播路由
	1. 全库表路由
	2. 全库路由
	3. 全实例路由
	4. 单播路由
	5. 阻断路由

根据解析上下文匹配数据库和表的分片策略，并生成路由路径。

对于携带分片键的SQL，根据分片键操作符不同可以划分为==单片路由==（分片键的操作符是等号）、==多片路由==（分片键的操作符是IN）和==范围路由==（分片键的操作符是BETWEEN），不携带分片键的SQL则采用==广播路由==。

###### #标准路由

标准路由是 ShardingSphere ==最为推荐==使用的分片方式，它的适用范围是==不包含关联查询或仅包含绑定表之间关联查询的SQL。== 当分片运算符是==等号==时，路由结果将落入单库（表），当分片运算符是==BETWEEN或IN==时，则路由结果不一定落入唯一的库（表），因此一条逻辑SQL最终可能被==拆分为多条用于执行的真实SQL。==举例说明，如果按照 order_id 的奇数和偶数进行数据分片，一个单表查询的SQL如下：

	SELECT * FROM t_order WHERE order_id IN (1, 2);
那么路由的结果应为：

	SELECT * FROM t_order_0 WHERE order_id IN (1, 2);
	SELECT * FROM t_order_1 WHERE order_id IN (1, 2);

==绑定表的关联查询与单表查询复杂度和性能相当==。举例说明，如果一个==包含绑定表==的关联查询SQL如下：

	SELECT * FROM t_order o JOIN t_order_item i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);

那么路由的结果应为：

	SELECT * FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);  SELECT * FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);

==SQL拆分的数目与单表是一致的。==

###### #笛卡尔路由

笛卡尔路由是最复杂的情况，它无法根据绑定表的关系定位分片规则，因此非绑定表之间的关联查询需要拆解为笛卡尔积组合执行。如果上个示例中的SQL并未配置绑定表关系，那么路由的结果应为：

	SELECT * FROM t_order_0 o JOIN t_order_item_0 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);  SELECT * FROM t_order_0 o JOIN t_order_item_1 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);  SELECT * FROM t_order_1 o JOIN t_order_item_0 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);  SELECT * FROM t_order_1 o JOIN t_order_item_1 i ON o.order_id=i.order_id  WHERE order_id IN (1, 2);

笛卡尔路由==查询性能较低==，需谨慎使用。全库表路由对于==不携带分片键==的SQL，则采取广播路由的方式。根据SQL类型又可以划分为==全库表路由==、==全库路由==、==全实例路由==、==单播路由==和==阻断路由==这5种类型。其中全库表路由用于处理对数据库中与其逻辑表相关的所有真实表的操作，主要包括不带分片键的DQL（数据查询）和DML（数据操纵），以及DDL（数据定义）等。例如：

	SELECT * FROM t_order WHERE good_prority IN (1, 10);

==则会遍历所有数据库中的所有表，逐一匹配逻辑表和真实表名==，能够匹配得上则执行。路由后成为

	SELECT * FROM t_order_0 WHERE good_prority IN (1, 10);  
	SELECT * FROM t_order_1 WHERE good_prority IN (1, 10);  
	SELECT * FROM t_order_2 WHERE good_prority IN (1, 10);  
	SELECT * FROM t_order_3 WHERE good_prority IN (1, 10);

##### #SQL改写

工程师面向逻辑表书写的SQL，并不能够直接在真实的数据库中执行，==SQL改写用于将逻辑SQL改写为在真实数据库中可以正确执行的SQL。==如一个简单的例子，若逻辑SQL为：

	SELECT order_id FROM t_order WHERE order_id=1;

假设该SQL配置分片键order_id，并且order_id=1的情况，将路由至分片表1。那么改写之后的SQL应该为：

	SELECT order_id FROM t_order_1 WHERE order_id=1;

##### #补列

再比如，Sharding-JDBC需要在结果归并时获取相应数据，但该数据并未能通过查询的SQL返回。这种情况主要是针对Group By和Order By。==结果归并时，需要根据Group By和Order By的字段项进行分组和排序，但如果原始SQL的选择项中并未包含分组或排序项，则需要对原始SQL进行改写。==先看一下原始SQL中带有结果归并所需信息的场景：

	SELECT order_id, user_id FROM t_order ORDER BY user_id;

由于使用user_id进行排序，在结果归并中需要能够获取到user_id的数据，而上面的SQL是能够获取到user_id数据的，因此无需补列。==如果选择项中不包含结果归并时所需的列，则需要进行补列，==如以下SQL：

	SELECT order_id FROM t_order ORDER BY user_id;

==由于原始SQL中并不包含需要在结果归并中需要获取的user_id，因此需要对SQL进行补列改写。==补列之后的SQL是：

	SELECT order_id, user_id AS ORDER_BY_DERIVED_0 FROM t_order ORDER BY user_id;

补列的另一种情况是==使用 AVG 聚合函数==。在分布式的场景中，使用 avg1 + avg2 + avg3 / 3 计算平均值并不正确，需要改写为（sum1 + sum2 + sum3) / (count1 + count2 + count3)。==这就需要将包含 AVG 的SQL改写为 SUM 和 COUNT== ，并在结果归并时重新计算平均值。例如以下SQL：

	SELECT AVG(price) FROM t_order WHERE user_id=1;

需要改写为：

	SELECT COUNT(price) AS AVG_DERIVED_COUNT_0, SUM(price) AS AVG_DERIVED_SUM_0 FROM t_order WHERE user_id = 1;

==然后才能结果归并正确的计算平均值。==

##### #分页修正

从多个数据库获取分页数据与单数据库的场景是不同的。假设每10条数据为一页，取第2页数据。==在分片环境下获取 LIMIT 10, 10，归并之后再根据排序条件取出前10条数据是不正确的。==举例说明，若SQL为：
	SELECT score FROM t_score ORDER BY score DESC LIMIT 1, 2;

下图展示了不进行 SQL 的改写的分页执行结果。![[Pasted image 20221216180232.png]]
正确的做法是将分页条件改写为 LIMIT 0,3 ，取出所有前两页数据，再结合排序条件计算出正确的数据。下图展示了进行SQL改写之后的分页执行结果。![[Pasted image 20221226155256.png]]
==越获取偏移量位置靠后数据，使用LIMIT分页方式的效率就越低。==有很多方法可以避免使用LIMIT进行分页。比如构建行记录数量与行偏移量的二级索引，或==使用上次分页数据结尾ID==作为下次查询条件的分页方式等。

分页信息修正时，如果使用占位符的方式书写SQL，则只需要改写参数列表即可，无需改写SQL本身。

##### #SQL执行

1. 连接模式
	1. 内存限制模式
	2. 连接限制模式
2. 自动化执行引擎
	1. 准备阶段
	2. 执行阶段

##### #内存限制模式

==使用此模式的前提是，ShardingSphere 对一次操作所耗费的数据库连接数量不做限制。==如果实际执行的SQL需要对某数据库实例中的200张表做操作，==则对每张表创建一个新的数据库连接==，并通过多线程的方式并发处理，以达成执行效率最大化。并且在SQL满足条件情况下，优先选择流式归并，以防止出现内存溢出或避免频繁垃圾回收情况。